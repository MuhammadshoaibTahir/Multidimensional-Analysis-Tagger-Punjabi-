import tkinter as tk
from tkinter import scrolledtext
import pandas as pd
import re

# Function to check for present indefinite tense (VPRT)
def check_present_indefinite(sentence):
    present_indefinite_patterns = [
        r'\bکردا\sاے\b', r'\bکر\sرہیا\sاے\b',  # Add more patterns as needed
    ]
    
    for pattern in present_indefinite_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(VPRT)'
    
    return None

# Function to check for past indefinite tense (VBD)
def check_past_indefinite(sentence):
    past_indefinite_patterns = [
        r'\bکیا\b', r'\bکر\sرہیا\sسی\b',  # Add more patterns as needed
    ]
    
    for pattern in past_indefinite_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(VBD)'
    
    return None

# Function to check for present continuous tense (VPRT)
def check_present_continuous(sentence):
    present_continuous_patterns = [
        r'\bرہیا\sاے\b', r'\bرہی\sاے\b',  # Add more patterns as needed
    ]
    
    for pattern in present_continuous_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(VPRT)'
    
    return None

# Function to check for past continuous tense (VBD)
def check_past_continuous(sentence):
    past_continuous_patterns = [
        r'\bرہیا\sسی\b', r'\bرہی\sسی\b', r'\bرئے\sسن\b', r'\bدیا\sسی\b', r'\بپیا\sسی\b',  # Add more patterns as needed
    ]
    
    for pattern in past_continuous_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(VBD)'
    
    return None

# Function to check for past perfect tense (VBD)
def check_past_perfect(sentence):
    past_perfect_patterns = [
        r'\بکردا\sسی\b',  # Add more patterns as needed
    ]
    
    for pattern in past_perfect_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(VBD)'
    
    return None

# Function to check for first person pronoun (FPP1)
def check_first_person_pronoun(sentence):
    first_person_pronouns = ['میں', 'ہم']
    
    for pronoun in first_person_pronouns:
        if re.search(r'\b' + re.escape(pronoun) + r'\b', sentence):
            return re.sub(r'\b' + re.escape(pronoun) + r'\b', f'{pronoun}_(FPP1)', sentence)
    
    return None

# Function to check for second person pronoun (SPP2)
def check_second_person_pronoun(sentence):
    second_person_pronouns = ['تو', 'تُسیں']
    
    for pronoun in second_person_pronouns:
        if re.search(r'\b' + re.escape(pronoun) + r'\ب', sentence):
            return re.sub(r'\b' + re.escape(pronoun) + r'\ب', f'{pronoun}_(SPP2)', sentence)
    
    return None

# Function to check for third person pronoun (TPP3)
def check_third_person_pronoun(sentence):
    third_person_pronouns = ['او', 'اوناں']
    
    for pronoun in third_person_pronouns:
        if re.search(r'\ب' + re.escape(pronoun) + r'\ب', sentence):
            return re.sub(r'\ب' + re.escape(pronoun) + r'\ب', f'{pronoun}_(TPP3)', sentence)
    
    return None

# Function to check for demonstrative pronoun (DEMP)
def check_demonstrative_pronoun(sentence):
    demonstrative_pronouns = ['یہ', 'وہ']
    
    for pronoun in demonstrative_pronouns:
        if re.search(r'\ب' + re.escape(pronoun) + r'\ب', sentence):
            return re.sub(r'\ب' + re.escape(pronoun) + r'\ب', f'{pronoun}_(DEMP)', sentence)
    
    return None

# Function to check for infinitives (TO)
def check_infinitives(sentence):
    infinitives = [
        'کرنا', 'دینا', 'پینا'
    ]
    
    for infinitive in infinitives:
        if re.search(r'\ب' + re.escape(infinitive) + r'\ب', sentence):
            return re.sub(r'\ب' + re.escape(infinitive) + r'\ب', f'{infinitive}_(TO)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for place adverbials (PLACE)
def check_place_adverbials(sentence):
    place_adverbials = [
        'اتے', 'اتاں', 'باہر', 'باہروں', 'آر پار', 'نال نال', 'آسے پاسے', 'آلے دو آلے', 'پچھے', 'پچھاں', 'دور', 'واڈھ', 'دوروں', 'تھلے', 'تھلے ول', 'اتے ول', 'زمین دے وچ', 'نیڑے', 'نیڑے توں', 'کتھے نہیں'
    ]
    
    for adverbial in place_adverbials:
        if re.search(r'\ب' + re.escape(adverbial) + r'\ب', sentence):
            return re.sub(r'\ب' + re.escape(adverbial) + r'\ب', f'{adverbial}_(PLACE)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for time adverbials (TIME)
def check_time_adverbials(sentence):
    time_adverbials = [
        'سبھ توں پہلاں', 'پہلاں', 'توں پہلاں', 'دوبارہ', 'مڑ', 'فیر', 'توں بعد', 'اس پچھوں', 'بعد اچ'
    ]
    
    for adverbial in time_adverbials:
        if re.search(r'\ب' + re.escape(adverbial) + r'\ب', sentence):
            return re.sub(r'\ب' + re.escape(adverbial) + r'\ب', f'{adverbial}_(TIME)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for hedges (HDG)
def check_hedges(sentence):
    hedges_structures = [
        r'\بہوسکدا\sاے\b',  # Structure 1: ہوسکدا اے
        r'\باندازا\b', r'\باندازاً\b', r'\باَنْدازاً\b',  # Structure 1: اندازا, اندازاً, اَنْدازاً
        r'\بکجھ\sایہو\b', r'\بجیہا\b', r'\بکجھ\sایہو\b', r'\بجئے\b',  # Structure 1: کجھ ایہو, جیہا, کجھ ایہو, جئے
        r'\بگھٹ\sوچھ\b',  # Structure 1: گھٹ وچ
        
        # Structure 2: when تقریبا follows or preceded by the numeric
        r'\بتقریبا\sاک\b', r'\بتقریبا\sدو\b', r'\بتقریبا\sتین\b', r'\بتقریبا\sچار\b', r'\بتقریبا\sپنج\b',
        r'\بتقریبا\sچھ\b', r'\بتقریبا\sست\b', r'\بتقریبا\sاٹھ\b', r'\بتقریبا\sنو\b', r'\بتقریبا\sدس\b',
        r'\بتقریبا\sگیارہ\b', r'\بتقریبا\sبارہ\b', r'\بتقریبا\sتیرہ\b', r'\بتقریبا\sچودہ\b',
        r'\بتقریبا\sپندرہ\b', r'\بتقریبا\sسولا\b', r'\بتقریبا\sسترہ\b', r'\بتقریبا\sاٹھارہ\b'
    ]
    
    for hedge_pattern in hedges_structures:
        if re.search(hedge_pattern, sentence):
            return re.sub(hedge_pattern, r'\گ<0>_(HDG)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for pro verb do (PROD)
def check_pro_verb_do(sentence):
    pro_verb_do_patterns = [
        r'\ب(\و+)\س(گیا)\ب', r'\ب(\و+)\س(ہویا)\ب', r'\ب(\و+)\س(کیتا)\ب', r'\ب(\و+)\س(دتا)\ب', 
        r'\ب(ہاں)\س(گیا)\ب', r'\ب(ہاں)\س(ہویا)\ب', r'\ب(ہاں)\س(کیتا)\ب', r'\ب(ہاں)\س(دتا)\ب',
        r'\ب(ہاں)\س(او)\ب', r'\ب(ہاں)\س(چل)\ب', r'\ب(ہاں)\س(آ)\ب', r'\ب(ہاں)\س(ویچ)\ب',
        r'\ب(وی)\س(گیا)\ب', r'\ب(وی)\س(ہویا)\ب', r'\ب(وی)\س(کیتا)\ب', r'\ب(وی)\س(دتا)\ب',
        r'\ب(وی)\س(چل)\ب', r'\ب(وی)\س(آ)\ب', r'\ب(وی)\س(او)\ب', r'\ب(وی)\س(آ)\ب',
        r'\ب(وی)\س(ویچ)\ب'
    ]
    
    for pro_verb_do_pattern in pro_verb_do_patterns:
        if re.search(pro_verb_do_pattern, sentence):
            return re.sub(pro_verb_do_pattern, r'\گ<0>_(PROD)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for verb complement (THVC)
def check_verb_complement(sentence):
    verb_complement_patterns = [
        r'\ب(\س+)\س(نہ)\س(سمجھ)\س(پایا)\ب', r'\ب(\س+)\س(نہ)\س(سمجھ)\س(آ)\س(وے)\ب', 
        r'\ب(\س+)\س(نہ)\س(سمجھ)\س(گے)\ب', r'\ب(\س+)\س(نہ)\س(سمجھ)\س(لگ)\ب', 
        r'\ب(پھر)\س(پِھریں)\س(لگ)\س(گیا)\ب', r'\ب(پھر)\س(پِھریں)\س(لگ)\س(گیا)\ب', 
        r'\ب(پھر)\س(لگ)\س(گیا)\س(گیا)\ب', r'\ب(پھر)\س(لگ)\س(گیا)\س(گیا)\ب'
    ]
    
    for verb_complement_pattern in verb_complement_patterns:
        if re.search(verb_complement_pattern, sentence):
            return re.sub(verb_complement_pattern, r'\گ<0>_(THVC)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for adjective complement (THAC)
def check_adjective_complement(sentence):
    adjective_complement_patterns = [
        r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\ب', r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(واہ)\ب',
        r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(ان)\س(جا)\ب', r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(خ)\ب',
        r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(ای)\س(ہا)\ب', r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(ن)\س(ہویا)\ب',
        r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(پ)\س(لگ)\ب', r'\ب(ہم)\س(نے)\س(آ)\س(کہ)\س(تھیا)\س(ن)\س(گ)\ب'
    ]
    
    for adjective_complement_pattern in adjective_complement_patterns:
        if re.search(adjective_complement_pattern, sentence):
            return re.sub(adjective_complement_pattern, r'\گ<0>_(THAC)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for WH questions (WHQU)
def check_wh_questions(sentence):
    wh_question_patterns = [
        r'\ب(کی)\ب', r'\ب(کیا)\ب', r'\ب(کون)\ب', r'\ب(کس)\ب', r'\ب(کس نے)\ب',
        r'\ب(کس دی)\ب', r'\ب(کس دا)\ب', r'\ب(کس نوں)\ب', r'\ب(کون ہے)\ب', r'\ب(کس ہے)\ب',
        r'\ب(کیہڑا)\ب', r'\ب(کتھے)\ب', r'\ب(کدوں)\ب', r'\ب(کتھاں)\ب', r'\ب(کدے)\ب',
        r'\ب(کیوں)\ب', r'\ب(کیویں)\ب', r'\ب(کس طرح)\ب'
    ]
    
    for wh_question_pattern in wh_question_patterns:
        if re.search(wh_question_pattern, sentence):
            return re.sub(wh_question_pattern, r'\گ<0>_(WHQU)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for Wh clause on subject position (WHSUB)
def check_wh_subj(sentence):
    wh_subj_patterns = [
        r'\ب(کس نے)\ب', r'\ب(کون)\ب', r'\ب(کیہڑا)\ب', r'\ب(کس دا)\ب', r'\ب(کیا)\ب'
    ]
    
    for wh_subj_pattern in wh_subj_patterns:
        if re.search(wh_subj_pattern, sentence):
            return re.sub(wh_subj_pattern, r'\گ<0>_(WHSUB)', sentence)
    
    return None  # Return None for sentences that do not match

# Function to check for Wh clause on object position (WHOBJ)
def check_wh_obj(sentence):
    wh_obj_patterns = [
        r'\ب(کس نے)\ب', r'\ب(کون)\ب', r'\ب(کہ)\ب', r'\ب(کدوں)\ب', r'\ب(جدوں)\ب',
        r'\ب(کتھاں)\ب', r'\ب(کدے)\ب', r'\ب(کتھے)\ب', r'\ب(کیوں)\ب'
    ]
    
    for wh_obj_pattern in wh_obj_patterns:
        if re.search(wh_obj_pattern, sentence):
            return re.sub(wh_obj_pattern, r'\گ<0>_(WHOBJ)', sentence)
    
    return None  # Return None for sentences that do not match


# Function to check for predictive model tags (PRMD)
def check_predictive_model(sentence):
    predictive_model_patterns = [
        r'\b(کرسکدا)\s(اے)\b', r'\b(سکدا)\s(اے)\b', r'\b(سکدے)\b', r'\b(کرسکدا)\s(سی)\b', r'\b(سکدے)\s(سن)\b'
    ]
    
    for pattern in predictive_model_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(PRMD)', sentence)
    
    return None

# Function to check for downtoners tags (DWNT)
def check_downtoners(sentence):
    downtoners_patterns = [
        r'\b(تقریبا)\b', r'\b(شاید)\b', r'\b(مشکل نال)\b', r'\b(لگ بھگ)\b', r'\b(کجھ حد تک)\b', r'\b(تھوڑا جیہا)\b'
    ]
    
    for pattern in downtoners_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(DWNT)', sentence)
    
    return None



# Function to check for emphatics tags (EMPH)
def check_emphatics(sentence):
    emphatics_patterns = [
        # بلکل
        r'\b(انج\s+بلکل)\b',  # Just like this or that
        r'\b(ہی\s+بلکل)\b',    # Completely
        r'\b(ای\s+بلکل)\b',    # Completely
        
        # سارا, پورا, مکمل
        r'\b(سارا)\b',         # Completely
        r'\b(پورا)\b',         # Emphatics if not following a verb
        r'\b(مکمل)\b',         # Emphatics
        
        # یقینا
        r'\b(یقینا)\b',        # Emphatics
        
        # سچی
        r'\b(سچی\s+سچی)\b',   # Emphatics
        r'\b(سچی)\b',          # Emphatics
        
        # سچی مچی
        r'\b(سچی\s+مچی)\b',   # Emphatics
        
        # پکی گل اے
        r'\b(پکی\s+گل\s+اے)\b', # Emphatics
        
        # ہاں ہاں
        r'\b(ہاں\s+ہاں)\b',   # Emphatics
        
        # بے شک
        r'\b(بے\s+شک)\b',      # Emphatics
        
        # ایہا تاں
        r'\b(ایہا\s+تاں)\b',   # Emphatics
        
        # صاف صاف
        r'\b(صاف\s+صاف)\b',   # Emphatics
        
        # ظاہری گل اے
        r'\b(ظاہری\s+گل\s+اے)\b', # Emphatics
        
        # پکا
        r'\b(پکا)\b'           # Emphatics if following a verb
    ]
    
    for pattern in emphatics_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(EMPH)', sentence)
    
    return None


# Function to check for Model of Necessity (NEMD)
def check_model_of_necessity(sentence):
    model_of_necessity_patterns = [
        r'\چاہیدا\sاے\b', r'\چاہیدا\sاو\b', r'\چاہیدا\sنیں\b',  # 1st structure
        r'\چاہیدا\sسی\b', r'\چاہیدا\sسن\b',
        r'\چاہیدا\sضرور\b',  # Additional pattern for ضرور
    ]
    
    for pattern in model_of_necessity_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(NEMD)'
    
    return None


# Function to check for Model of Possibility (POMD)
def check_model_of_possibility(sentence):
    model_of_possibility_patterns = [
        r'\bہوسکدا\sاے\b', r'\bہوسکدی\sاے\b', r'\bہوسکدے\sاے\b',
    ]
    
    for pattern in model_of_possibility_patterns:
        if re.search(pattern, sentence):
            return sentence.strip() + '_(POMD)'
    
    return None

# Function to check for discourse particles (DPAR)
def check_discourse_particles(sentence):
    discourse_particle_patterns = [
        r'\b(اچھا)\b', r'\b(بھلے\sہی)\b', r'\b(ہن)\b',  # Single word discourse particles
        r'\b(چلو)\b', r'\b(کوئی\sگل\sنئی)\b', r'\b(کوئی\sگل\sنہیں)\b'  # Start of sentence discourse particles
    ]
    
    for pattern in discourse_particle_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(DPAR)', sentence)
    
    return None

# Function to check for Coordinate conjunctions (PHC)
def check_coordinate_conjunctions(sentence):
    coordinate_conjunction_patterns = [
        r'\b(اس\sلئی)\b', r'\b(نہ\sہی)\b', r'\b(لیکن)\b', r'\b(پر)\b', r'\b(تے)\b', r'\b(تاں)\b', r'\b(اجے\sتک)\b',
        r'\b(اجے\sتک)(?=.*\?)',  # اجے تک as "yet" after interrogative sentence
        r'\b(نہیں|نئی)\s+(.*\s+)?اجے\sتک\b',  # اجے تک as "yet" after negation
    ]
    
    for pattern in coordinate_conjunction_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(PHC)', sentence)
    
    return None


# Function to check for Conjuncts (CONJ)
def check_conjuncts(sentence):
    conjunct_patterns = [
        r'\b(الٹا)\b(?!\s+نے\s+)',  # الٹا as conjunct, not following verb نے
        r'\b(جیویں)\b',  # جیویں as conjunct
        r'\b(ایس\sپاروں)\b',  # ایس پاروں as conjunct
        r'\b(بلکہ|اس\sتوں\sبعد|ایس\sطرحاں|ایس\sنالوں|اس\sلئی|نہیں\sتاں|نہیں\sتے)\b',  # Various conjuncts
        r'\b(ہور)\b(?!.*\b(نواز|چودھری|سردار|مکین))',  # ہور as conjunct, not preceding specific nouns/pronouns
    ]
    
    for pattern in conjunct_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(CONJ)', sentence)
    
    return None

# Function to check for Conditional adverbial subordinators (COND)
def check_conditional_subordinators(sentence):
    cond_patterns = [
        r'\b(جے)\b(?!\s*کیوں\b)',  # جے as conditional subordinate, not preceded by کیوں
        r'\b(کیوں\s*جے)\b',  # کیوں جے as a different entity
        r'\b(جدوں\sتک)\b',  # جدوں تک as conditional subordinate
    ]
    
    for pattern in cond_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(COND)', sentence)
    
    return None

def check_predictive_adjective(sentence):
    pred_adj_pattern = r'\b(\S+)\s+(\S+)\s+(اے)\b'  # Pattern for predictive adjective
    if re.search(pred_adj_pattern, sentence):
        return re.sub(pred_adj_pattern, r'\1_\2_(PRED)', sentence)
    return None

def check_seem_appear(sentence):
    seem_appear_patterns = [
        r'\b(ظاہر)\b', r'\b(یو)\b', r'\b(یور)\b',  # Add more patterns as needed
    ]
    
    for pattern in seem_appear_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(SAPR)', sentence)
    
    return None


def tag_words_as_vb(sentence):
    # Specific words to be tagged as RB
    words_to_tag = r'ودھ|ودھدے|ودھدی|ودھدیاں|ودھیا|ودھن|ودھنا|ودھا|ودھ|اٹھ|اڈ|آ|بچ|بدل|بک|بلا|بن|بھر|بھل|پاڑ|پا|پج|پڑھ|پھڑ|پی|تر|ٹٹ|ٹور|ٹیک|جا|جاگ|جت|چڑھ|چک|چگ|چل|دی|دس|ڈٹ|ڈگ|رک|رکھ|رل|رہ|روک|رو|سن|سوچ|کٹ|کر|کہ|کھا|کھو|گوا|لٹک|لڑ|لک|لے|مٹ|مر|مڑ|مک|ملا|نچڑ|ہس|ہلا|وٹ|وڑ|وک|ویچ|اکھ|اتر|اٹھ|اجڑ|اچھل|اڈ|اڈیک|اکتا|اکسا|اکھاڑ|اگ|اگل|الٹ|الجھ|ابھر|اپڑ|اپنا|اٹک|اچھال|اڑ|الٹ|اوڑھ|آکڑ|بڑبڑا|بلا|بکھر|بٹھا|بجھا|بچا|بدل|بڑھ|بس|بک|بکھیر|بگھو|بلا|بنا|بندھ|بنھ|بہا|بھل|بھن|بھٹک|بھر|بھگت|بھونک|بول|بوندل|بیاہ|بیٹھ|پٹ|پھوک|پوج|پاٹ|پال|پا|پرت|پرکھ|پڑھ|پکار|پکا|پکڑ|پگھل|پلا|پہنچ|پہن|پھٹ|پھر|پھڑ|پھس|پھیر|پھیل|پٹ|پونجھ|تر|تلک|تڑف|تک|تھک|توڑ|تول|تیر|ٹپ|ٹٹ|ٹر|ٹکر|ٹک|ٹل|ٹہل|ٹھاو|ٹھپ|ٹھٹ|ٹھر|ٹھکرا|ٹھل|ٹھہر|ٹھوک|ٹوک|جڑ|جاچ|جاگ|جا|جانچ|جان|جاوڑ|جاگ|جل|جم|جھک|جھاڑ|جھاک|جھٹک|جھگڑ|جھل|چھپ|چھڈ|چک|چاڑ|چاہ|چٹر|چٹ|چڑھ|چگ|چل|چمبڑ|چمک|چم|چھاپ|چھا|چیر|چیک|خرید|دس|دفنا|دکھا|دلا|دھڑک|دھکیل|دوڑ|دھو|دیکھ|دے|ڈگ|ڈانٹ|ڈرا|ڈس|ڈک|ڈل|ڈھل|ڈبو|ڈول|رچ|رڑک|رڑھ|رکھ|رک|رل|رہ|روڑ|روک|رے|رینگ|سٹ|سڑ|سکھ|سنبھال|سوچ|سو|سی|کت|کٹ|کچل|کڈھ|کر|کہ|کھا|کھچ|کھڑک|کھسک|کھلو|کھوج|کھول|کھو|کھیڈ|گڈ|گھٹ|گھسیٹ|گھل|گھم|گھول|گوا|گونج|لبھ|لجا|لد|لڑ|لک|لکھ|لگ|لیا|مار|مچل|مر|مڑ|مک|مل|منگ|من|نکل|نہا|ہو|واڑ|وج|وچھ|ودھ|وڈ|وڑ|وس|وک|وگڑ|ول|ونڈ|ویچ|ویکھ|اڈ|ابل|ابھر|اتر|اٹھ|اجڑ|اچھل|اڑ|اکھڑ|اگل|اگ|الجھ|اونگھ|ابال|اپڑ|اپنا|اٹک|چک|اڈیک|اکسا|اکھاڑ|اکھوا|اگھڑ|امڈ|آکڑ|آکھ|بجھا|بیٹھ|بجھ|بڑبڑ|بڑھک|بھر|بھل|بھوک|بٹھاؤ|بک|بگڑ|بلک|بنس|بھ|بیج|بال|باہ|بتاو|بٹ|بٹھا|بجاؤ|بچ|بچھ|بخش|بدل|بڑ|برس|بڑک|بسک|بس|بکھر|بگھار|بگھو|بل|ب|بنھاؤ|بنھ|بنا|بندھ|بہک|بہ|بھڑک|بھک|بھگت|بھج|بھیو|بھاگ|بھال|بھا|بھانپ|بھاو|بھپ|بھٹر|بھٹکا|بھٹک|بھرم|بھڑ|بھیج|بول|بیاہ|بیت|بیڑ|پچھتاو|پرکھ|پھٹ|پھڑک|پھس|پیٹھ|پڑ|پکار|پن|پوج|پور|پونجھ|پڑاؤ|پس|پگھل|پلاؤ|پنج|پھر|پھینٹ|پی|پاٹ|پاڑ|پال|پتھ|پتھراؤ|پٹخ|پٹک|پج|پچکار|پچ|پچھ|پچھاتا|پچھاڑ|پچھا|پچھتا|پچھڑ|پدھار|پرچ|پرت|پرچار|پرس|پرگٹاؤ|پرگٹ|پروس|پرو|پڑتال|پڑچول|پڑدا|پڑھا|پڑھ|پسر|پک|پکڑ|پلا|پلٹ|پلچ|پل|پلوس|پہنچ|پہچا|پہ|پھیل|پھدک|پھل|پھنڈ|پھسل|پھاٹ|پھاڈ|پھاڑ|پھاہ|پھب|پھٹنا|پھرک|پھرول|پھڑ|پھڑ|پھک|پھوک|پھول|پھیر|پھی|پھیہ|پواؤ|پوس|پو|پونج|پوہنچ|پیچ|پیڑ|پیو|تر|تل|تٹھ|تڑک|تن|تھڑک|تھڑ|تو|تڑ|تلک|تنگھ|تار|تاڑ|تاک|تانگھ|تپ|تجر|تراش|تراہ|تراؤ|ترس|تڑپ|تڑف|تک|تھک|تھاپڑ|تھپ|تھپک|تھتھلا|تھٹر|تھرک|تھل|تھم|تھوپ|تھیو|تور|توڑ|توک|تیاگ|تیر|تیک|ٹر|ٹک|ٹانک|ٹپک|ٹٹ|ٹکرا|ٹکر|ٹل|ٹمٹما|ٹنگ|ٹہل|ٹھک|ٹھلھ|ٹھار|ٹھا|ٹھپ|ٹھٹ|ٹھٹھر|ٹھر|ٹھکرا|ٹھکور|ٹھگ|ٹھل|ٹھنک|ٹھہر|ٹھوک|ٹور|ٹوک|ٹول|ٹوہ|جت|جٹ|جڑ|جد|جیو|جاپ|جاس|جال|جا|جانچ|جپ|جچ|جر|جکڑ|جک|جگ|جگا|جل|جم|ج|جھر|جھک|جھلاؤنا|جھلس|جھڑک|جھاڑ|جھاک|جھاگ|جھانک|جھپک|جھٹ|جھٹک|جھٹلا|جھجک|جھڑپ|جھڑ|جھس|جھگڑ|جھل|جھلک|جھم|جھمک|جھنجوڑ|جھوٹ|جھور|جھوک|جھول|جھومنا|جواؤ|جوجھ|جوڑ|جی|چھپ|چھڈ|چونک|چبھ|چپا|چٹ|چرا|چراؤ|چڑ|چس|چکوا|چگ|چم|چ|چنڈ|چنگھ|چھپاو|چپک|چپکاؤ|چتر|چتاؤ|چتھ|چٹک|چر|چڑاؤ|چلاؤ|چمڑنا|چننا|چھڑ|چار|چاڑھ|چا|چاہو|چاہید|چاو|چاؤ|چب|چبک|چپکاو|چروا|چڑھ|چسک|چکھ|چل|چمڑ|چمک|چہک|چھڈاؤ|چھڑاؤ|چھڑک|چھلک|چھہ|چھڑوا|چھل|چھنک|چھاپ|چھانٹ|چھا|چھاؤ|چھب|چھپا|چھٹ|چھڑا|چھک|چھکاؤ|چھنڈ|چھ|چھوڑ|چھو|چھونک|چھوہ|چھیڑ|چھی|چوپ|چور|چوس|چوک|چیر|چیک|خرچ|خرید|دس|دڑا|دکھاؤ|دکھ|دہراؤ|دھم|دت|دھیا|دب|دباؤ|دبک|دبوچ|دڑھک|دفناؤ|دکھال|دلا|دہاڑ|دھکھ|دھل|دھواؤ|دھار|دھاڑ|دھا|دھر|دھڑک|دھس|دھک|دھکیل|دھمکا|دھو|دھوڑ|دھوہ|دی|دیکھ|ڈب|ڈسک|ڈک|ڈلھ|ڈنگ|ڈھک|ڈھونڈ|ڈگ|ڈاہ|ڈپھ|ڈٹ|ڈٹھ|ڈر|ڈس|ڈنگاؤ|ڈنگنا|ڈنگی|ڈہنا|ڈھلک|ڈھا|ڈھال|ڈھالنا|ڈھاہ|ڈھاو|ڈھل|ڈھ|ڈھہ|ڈھو|ڈھی|ڈوب|ڈول|ڈولھ|ڈیگ|رجھ|رجھاؤ|رڑھ|رس|رش|رک|رل|رمک|رنھ|رو|رڑک|رنگ|رہ|رٹ|رج|رچ|رڑ|رڑو|رگڑ|رم|رند|روک|رول|ریج|رینگ|سد|سٹ|سج|سجھ|سدھار|سک|سلجھ|سلگ|سنگھ|س|سسک|سکھ|سمٹ|سمر|سنج|سیو|سادھ|ساڑ|سامبھ|ستا|سراہ|سرک|سرو|سڑ|سستا|سل|سلگھ|سماؤ|سمجھا|سمیٹ|سنبھال|سنجھا|سنگڑ|سہار|سہ|سہیڑ|سوار|سوبھ|سوچ|سو|سونپ|سیک|سی|شرم|کھڑ|کھول|کتر|کٹ|کٹھ|کچل|کد|کڑھ|کسک|کھب|کھل|کھلار|کاڑھ|کت|کج|کچھ|کس|کمب|کہ|کھبھ|کھٹ|کھرچ|کھرک|کھچ|کھڈ|کھس|کھلر|کھا|کھپ|کھٹک|کھر|کھڑک|کھڑھ|کھسک|کھنگال|کھنگھ|کھہ|کھو|کھوج|کھوہ|کھیڈ|کوس|کیہ|گھل|گڈ|گزر|گم|گنج|گند|گھٹ|گھس|گھم|گ|گنواؤ|گا|گل|گاہ|گج|گد|گرج|گرہ|گڑ|گنڈھ|گہ|گھور|گھما|گھر|گھبرا|گھرک|گھڑ|گھسیٹ|گھول|گھیر|گواچ|گوڈ|گور|گونج|گوہ|گیدڑ|گیر|لی|لبھ|لٹ|لجھ|لد|لپٹ|لشک|لکھ|لا|لبڑ|لب|لتاڑ|لٹدے|لٹک|لجا|لڈ|لرز|لڑ|لڑکھڑا|لڑنا|لڑی|لک|لگ|للکار|لمک|لنگھ|لہر|لہ|لوا|لوچ|لوڑ|لوس|لیٹ|مٹھ|مچ|مچھ|مڑ|مسکرا|مشک|مکر|مند|منڈ|موت|متھ|مٹ|مدھ|ماپ|مار|مانج|مد|مدھول|مر|مسل|منا|منگ|منگیج|مہک|موڑ|مول|مو|موہ|میٹ|میچ|میس|نس|نچڑ|نہا|نبڑ|نب|نبھ|نپٹ|نکل|نکھر|نگل|ناپ|ناچ|نبیڑ|نپ|نتار|نٹھ|نچ|نچنا|نچوڑ|نکھڑ|نگ|نواز|ہڑ|ہس|ہک|ہل|ہار|ہٹ|ہر|ہڑپ|ہنڈ|ہو|ہونا|ہونجھ|ہونک|ھار|ھاک|ھٹ|ھرا|ھس|ھوٹ|وس|وچر|وچل|وچھڑ|وچھ|وڈنا|وڈھ|ورچا|ور|وک|وکھ|وگڑ|ولک|واڑ|وانگ|واہ|وج|وچ|ودھ|ورت|وسار|وصول|وکھر|وگ|ول|ونج|ونڈ|ون|وہ|ویچ|ویکھ|ویل|ویھ|یرک|ودھوا|ودھدا|ودھوائو|ودھو|ودھیو|ودھنی|ودھانی|ودھاں|ودھیے|ودھایے|ودھے|ودھیاں|ودھی|ودھاندے|ودھاندی|ودھاندا|ودھاندیاں|ودھواندے|ودھواندی|ودھواندا|ودھواندیاں|ودھوائی|ودھوایے|ودھوایاں|ودھان|ودھوان|ودھواون|اٹھ|اٹھدے|اٹھدی|اٹھدیاں|اٹھیا|اٹھن|اٹھنا|اٹھا|اٹھوا|اٹھدا|اٹھوائو|اٹھو|اٹھیو|اٹھنی|اٹھانی|اٹھاں|اٹھیے|اٹھایے|اٹھے|اٹھیاں|اٹھی|اٹھاندے|اٹھاندی|اٹھاندا|اٹھاندیاں|اٹھواندے|اٹھواندی|اٹھواندا|اٹھواندیاں|اٹھوائی|اٹھوایے|اٹھوایاں|اٹھان|اٹھوان|اٹھواون|اڈ|اڈدے|اڈدی|اڈدیاں|اڈیا|اڈن|اڈنا|اڈا|اڈوا|اڈدا|اڈوائو|اڈو|اڈیو|اڈنی|اڈانی|اڈاں|اڈیے|اڈایے|اڈے|اڈیاں|اڈی|اڈاندے|اڈاندی|اڈاندا|اڈاندیاں|اڈواندے|اڈواندی|اڈواندا|اڈواندیاں|اڈوائی|اڈوایے|اڈوایاں|اڈان|اڈوان|اڈواون|آ|آدے|آدی|آدیاں|آیا|آن|آنا|آ|آوا|آدا|آوائو|آو|آیو|آنی|آں|آیے|آیے|آے|آیاں|آی|آندے|آندی|آندا|آندیاں|آواندے|آواندی|آواندا|آواندیاں|آوائی|آوایے|آوایاں|آن|آوان|آواون'

    # Tag each occurrence of the specific words in the sentence
    tagged_sentence = re.sub(rf'\b({words_to_tag})\b', r'\1_(VB)', sentence)
    
    return tagged_sentence


# Define the function to tag Analytical Negation
def tag_analytical_negation(sentence):
    analytical_negation_pattern = re.compile(r'(نہیں|نہ|نا)\s+(\S+)', re.UNICODE)
    matches = analytical_negation_pattern.finditer(sentence)
    for match in matches:
        if ' ' + match.group(2) + ' ' in sentence:
            sentence = sentence.replace(' ' + match.group(2) + ' ', f' (xxO)_{match.group(2)} ')
    return sentence


def tag_words_as_NN(sentence):
    # Specific words to be tagged as NN
    words_to_tag = [
        "روغن", "روگ", "رولا", "رومال", "رئیس", "زُلف", "زبان", "زچہ", "زحمت", "زخم",
        "زر", "زراعت", "زرتشت", "زردی", "زکام", "زلزلہ", "زم", "سُکھ", "سُورما", "سُول",
        "سِپاہی", "سِر", "سِکہ", "سِمے", "سِیر", "ساجن", "ساحل", "ساخت", "ساز", "ساس",
        "سالگرا", "سالن", "سامان", "سپ", "ساون", "سایہ", "اُسترا", "حنا", "نان", "چھل",
        "حسن", "لوٹا", "جنگ", "شے", "لوک", "شاعر", "فیض", "وارث", "سچ", "بدی", "سرگرمی",
        "جرمانہ", "چتر", "نڈر", "چاہت", "درد", "سوچ", "لہو", "چکی", "مکا", "اڈا", "کلی",
        "مقدس", "برکی", "منگنی", "کیڑا", "غالب", "جلد", "سوٹی", "گائے", "روئی", "بیج",
        "جھلہ", "امانت", "امتیاز", "جھگی", "جیت", "ہوکے", "روڑ", "شوکت", "غنی", "گری",
        "خادم", "وستی", "لیر", "ملائی", "چھاپہ", "کوڑی", "بھیجا", "لین", "منصب", "پرچہ",
        "کتا", "اتار", "کلو", "دوائی", "توڑی", "دکھ", "محل", "گارہ", "ہیرا", "خطا", "کڑم",
        "فتوا", "ڈھیر", "دید", "روپ", "نگر", "آکڑ", "ماپے", "ملپ", "دوری", "دیا", "سونا",
        "ویاہ", "جرم", "راج", "ساتھ", "شکار", "فن", "بگھت", "اجاڑ", "فرق", "بابل", "نہاو",
        "جشن", "بستا", "گھڑا", "توت"
    ]

    # Tag each occurrence of the specific words in the sentence
    tagged_sentence = re.sub(rf'\b({"|".join(words_to_tag)})\b', r'\1_(NN)', sentence)

    return tagged_sentence

def tag_words_as_RB(sentence):
    adverb_to_tag = [
        "اُبھّڑواہ", "اُبّھے جیہاہیں", "آپ مُہارے", "اُپّر ولّ", "اُپرنت", "اُپّروتھلی", "اُپّروں", "آپس وِچ", "آپے", "اُتاں",
        "اتِرِکت", "اُتلے منوں", "اُتھائیں", "اِتّھوں", "اِتّھے", "اُتّوں", "اُتّوں ڑِتّی", "اٹاکُٹ", "اٹھّے پہر", "اَجّ بھلک",
        "اَجّ کلّھ", "اَجّ ہی", "اجائیں", "اجّو", "اجے", "آجیون", "اچانک", "اُچر", "اُچِر", "اِچر", "اچنچیت", "اچھوپلے", "احتیاطاً",
        "آخردار", "اُدالے", "اِدّاں", "ادب نال", "ادّھ وِچالے", "اُدّر", "اِدّھر", "ادھواٹے", "اُدوکنا", "اڈّو اڈّ", "آر پار",
        "ارادتاً", "اِراکے نال", "اِرد گِرد", "اُرھاں", "اُروار", "اُروار پار", "اُرے", "اُرِیوں", "اسمانوں", "اسّی پرنے", "اُشیر جیہار",
        "اصلوں", "اصولاً", "اعلانیا", "اِک دم", "اِک دِھر", "اِک لکھت", "اِک نال", "اِک وڈّھوں", "اُکّا", "اکٽر", "اِکّر", "اکسمات",
        "اکلاّ اکلاّ", "اِکلونجھے", "اِکّن", "اُکہاں", "اکھّوں پروکھے", "اِکیراں", "اگاڑی پِچھاڑی", "اگانھ", "اگاہ", "اگاؤں",
        "اگّڑ پِچّڑ", "اگّلوانڈھے", "اگّوں", "اگّوں پِچّھوں", "اگّے", "اگّے ای", "اگّے پِچّھے", "اگّے توں", "اگّے واسطے",
        "اگیرے", "اگِّیوں", "اُلٹ پُلٹ", "آمنے جیہامہنے", "اِنّبِنّ", "انترگت", "اُنج", "اِنج", "اندر اندر", "اندر خانے", "اندر کھاپر",
        "اندروں اندر", "اَندھا دھُندھ", "انگ سنگ", "انگیدار", "اُننج", "اُننج ہی", "انّھیواہ", "انوجیہار", "آہستہ", "اوتھوں", "اَوتھے",
        "اوداں", "اودن", "اودھر", "اَودھر", "اودروں", "اودوں", "اُودوں", "اودوں توں", "اَوستن", "اوشّ", "اُوں", "اوویں", "اِویں",
        "ایتداں", "ایتھوں", "ایتھے", "ایداں", "ایدکاں", "ایدھر", "ایدھر اودھر", "ایدھروں", "ایدوں", "ایں", "اینے نوں", "ایوں", "ایویں",
        "باجھ", "بار بار", "بالکُل", "بالکُل نہیں", "بانسبت", "باہر اندر", "باہروار", "باو جود", "بجائے", "بِجلی وانگ", "بحُکم", "بخوبی",
        "بدستور", "بدلے", "بدوبدی", "بدولت", "بُڈّھے وارے", "بذات خود", "بذریعہ", "براستا", "برخِلاف", "بِسمِلاّ", "بظاہر", "بعد",
        "بعد وِچ", "بِلاقصور", "بلامُعاوضہ", "بِلاناغہ", "بلپوروک", "بلونت", "بمُوجب", "بن ٹھن کے", "بنّے", "بھال وِچ", "بہُبِدھ",
        "بہُبھانت", "بہُت کہکے", "بہرہال", "بھروسے نال", "بُھلّ بُھلیکھے", "بَھلکے", "بھلی بھانت", "بھُنجے", "بھولے بھا", "بُوہے بُوہے",
        "بے تحاشہ", "بے دِلی نال", "بے رحمی نال", "بے روک ٹوک", "بے سبب", "بے شک", "بے وجہ", "بے وقت", "بیٹھے", "بِٹھائے", "پا لا کے",
        "پاسیوں", "پالو پال", "پانال پرنے", "پُٹھّے پَیری"
        ]
   
    # Join the list of words into a pattern for regex
    pattern = r'\b(?:{})\b'.format('|'.join(map(re.escape, adverb_to_tag)))
    
    # Tag each occurrence of the specific words in the sentence
    tagged_sentence = re.sub(pattern, r'\g<0>_(RB)', sentence)

    return tagged_sentence


# Function to mark split auxiliary structures
def mark_split_auxiliary(sentence):
    # Define Urdu split auxiliary pattern (lexical category between verb and auxiliary)
    split_auxiliary_pattern = r'\b(\S+)\s+(.+)\s+(\S+)\b'
    
    # Applying regex pattern to match split auxiliary structures
    match = re.search(split_auxiliary_pattern, sentence)
    if match:
        # Marking the split auxiliary structure
        marked_sentence = re.sub(split_auxiliary_pattern, r'\1_\2_\3_(SPAU)', sentence)
        return marked_sentence
    else:
        return sentence
    
# Function to detect synthetic negation
def detect_synthetic_negation(sentence):
    synthetic_negation_patterns = [
        r'\b(نہ\sکوئی\sاور)\b', r'\b(نہ\sکوئی\sرہ)\b',
        r'\b(نہ\sکوئی\sای)\b', r'\b(نہ\sکوئی\sتھا)\b',
        r'\b(نہ\sکوئی\sخ)\b', r'\b(نہ\sکوئی\sچ)\b',
        r'\b(نہ\sکوئی\sنہیں)\b', r'\b(نہ\sکوئی\sکیہیا)\b'
    ]
    
    for pattern in synthetic_negation_patterns:
        if re.search(pattern, sentence):
            return re.sub(pattern, r'\1_(SYNE)', sentence)
    
    return None  # Return None for sentences that do not match


# Function to detect tags based on rules
def detect_conditional_adverbial(sentence):
    # Rule for detecting 'جدوں تک' and 'جے' as Conditional Adverbial Subordinators (COND)
    cond_tags = []
    
    # Detect 'جدوں تک'
    if 'جدوں تک' in sentence:
        sentence = sentence.replace('جدوں تک', 'جدوں تک_(COND)')
    
    # Detect 'جے' with exceptions
    words = sentence.split()
    for i, word in enumerate(words):
        if word == 'جے':
            if i > 0 and words[i-1] == 'کیوں':
                continue  # Skip 'جے' when preceded by 'کیوں'
            if i > 0 and re.search(r'\wجے$', words[i-1]):
                continue  # Skip 'جے' when directly preceded by any morpheme without space
            sentence = sentence.replace('جے', 'جے_(COND)', 1)
    
    return sentence

# Function to check for that deletion (THATD)
def check_that_deletion(sentence):
    that_deletion_patterns = [
        r'\bیہ\b[\s\w]+\bجو\b[\s\w]+\bسے\b', r'\bیہ\b[\س\و]+\بکہ\b[\س\و]+\بنے\b',  # Pattern examples for "that deletion" structures
        r'\bجو\b[\س\و]+\بکہ\b[\س\و]+\بگیا\b'
    ]
    
    for thatd_pattern in that_deletion_patterns:
        if re.search(thatd_pattern, sentence):
            return re.sub(thatd_pattern, r'\گ<0>_(THATD)', sentence)
    
    return None  # Return None for sentences that do not match


def tag_public_verbs(sentence):
    public_verbs = [
        "پہچاننا", "پہچانا", "پہچاندا ہے", "پہچاندے ہوئے", "شامل کرنا", "شامل کردا ہے", "شامل کردے ہوئے", "شامل کیتا",
        "اعتراف کرنا", "اعتراف کردا ہے", "اعتراف کردے ہوئے", "اعتراف کیتا", "تصدیق کرنا", "تصدیق کردا ہے", "تصدیق کردے ہوئے", 
        "تصدیق کیتا", "اتفاق کرنا", "اتفاق کردا ہے", "اتفاق کردے ہوئے", "اتفاق کیتا", "الزام دینا", "الزام دیتا ہے", 
        "الزام دیتے ہوئے", "الزام لگایا", "اعلان کرنا", "اعلان کردا ہے", "اعلان کردے ہوئے", "اعلان کیتا", "بحث کرنا", 
        "بحث کردا ہے", "بحث کردے ہوئے", "بحث کیتی", "دعویٰ کرنا", "دعویٰ کردا ہے", "دعویٰ کردے ہوئے", "دعویٰ کیتی", 
        "شرط لگانا", "شرط لگادی ہے", "شرط لگادے ہوئے", "شیخی خوری کرنا", "شیخی خوری کردا ہے", "شیخی خوری کردے ہوئے", 
        "شیخی خوری کیتی", "تصدیق کرنا", "تصدیق کردا ہے", "تصدیق کردے ہوئے", "تصدیق کیتی", "دعویٰ کرنا", "دعویٰ کردا ہے", 
        "دعویٰ کردے ہوئے", "دعویٰ کیتا", "تبصرہ کرنا", "تبصرہ کردا ہے", "تبصرہ کردے ہوئے", "تبصرہ کیتا", "شکایت کرنا", 
        "شکایت کردا ہے", "شکایت کردے ہوئے", "شکایت کیتی", "اقرار کرنا", "اقرار کردا ہے", "اقرار کردے ہوئے", "اقرار کیتی", 
        "اقرار کرنا", "اقرار کردا ہے", "اقرار کردے ہوئے", "اقرار کیتی", "اعتماد کرنا", "اعتماد کردا ہے", "اعتماد کردے ہوئے", 
        "اعتماد کیتی", "تصدیق کرنا", "تصدیق کردا ہے", "تصدیق کردے ہوئے", "تصدیق کیتی", "مسابقت کرنا", "مسابقت کردا ہے", 
        "مسابقت کردے ہوئے", "مسابقت کیتی", "منتقل کرنا", "منتقل کردا ہے", "منتقل کردے ہوئے", "منتقل کیتی", "اعلان کرنا", 
        "اعلان کردا ہے", "اعلان کردے ہوئے", "اعلان کیتی", "انکار کرنا", "انکار کردا ہے", "انکار کردے ہوئے", "انکار کیتی", 
        "ظاہر کرنا", "ظاہر کردا ہے", "ظاہر کردے ہوئے", "ظاہر کیتی", "چلانا", "چلاتا ہے", "چلاتے ہوئے", "چلا دیا", 
        "وضاحت کرنا", "وضاحت کردا ہے", "وضاحت کردے ہوئے"
    ]
    
    # Join the list of public verbs into a pattern for regex
    pattern = r'\b(?:{})\b'.format('|'.join(map(re.escape, public_verbs)))
    
    # Tag each occurrence of the specific public verbs in the sentence
    tagged_sentence = re.sub(pattern, r'\g<0>_(PUBV)', sentence)

    return tagged_sentence


def tag_private_verbs(sentence):
    private_verbs = [
        "قبول کرنا", "قبول کردا", "قبول کررہیا", "قبول کیتا", "اندازہ کرنا", "اندازہ کردا", "اندازہ کررہیا", "اندازہ کیتا", 
        "معلوم کرنا", "معلوم کردا", "معلوم کررہیا", "معلوم کیتا", "فرض کرنا", "فرض کردا", "فرض کررہیا", "فرض کیتا", 
        "یقین کرنا", "یقین کردا", "یقین کررہیا", "یقین کیتا", "حساب کرنا", "حساب کردا", "حساب کررہیا", "حساب کیتا", 
        "چیک کرنا", "چیک کردا", "چیک کررہیا", "چیک کیتا", "نتیجہ نکالنا", "نتیجہ نکالدا", "نتیجہ نکال رہیا", "نتیجہ نکالیا", 
        "قیاس کرنا", "قیاس کردا", "قیاس کررہیا", "قیاس کیتا", "غور کرنا", "غور کردا", "غور کررہیا", "غور کیتا", 
        "فیصلہ کرنا", "فیصلہ کردا", "فیصلہ کررہیا", "فیصلہ کیتا", "نتیجہ اخذ کرنا", "نتیجہ اخذ کردا", "نتیجہ اخذ کررہیا", 
        "نتیجہ اخذ کیتا", "سمجھنا", "سمجھدا", "سمجھ رہیا", "سمجھیا", "ثابت کرنا", "ثابت کردا", "ثابت کررہیا", "ثابت کیتا", 
        "طے کرنا", "طے کردا", "طے کررہیا", "طے کیتا", "پرکھنا", "پرکھدا", "پرکھ رہیا", "پرکھیا", "دریافت کرنا", 
        "دریافت کردا", "دریافت کررہیا", "دریافت کیتا", "شک کرنا", "شک کردا", "شک کررہیا", "شک کیتا", "خواب دیکھنا", 
        "خواب دیکھدا", "خواب دیکھ رہیا", "خواب دیکھیا", "یقینی بنانا", "یقینی بناندا", "یقینی بنا رہیا", "یقینی بناییا", 
        "قائم کرنا", "قائم کردا", "قائم کررہیا", "قائم کیتا", "تخمینہ لگانا", "تخمینہ لگاندا", "تخمینہ لگا رہیا", 
        "تخمینہ لگاییا", "توقع کرنا", "توقع کردا", "توقع کررہیا", "توقع کیتا", "خواب دیکھنا", "خواب دیکھدا", "خواب دیکھ رہیا", 
        "خواب دیکھیا", "ڈرنا", "ڈردا", "ڈر رہیا", "ڈریا", "محسوس کرنا", "محسوس کردا", "محسوس کررہیا", "محسوس کیتا", 
        "تلاش کرنا", "تلاش کردا", "تلاش کررہیا", "تلاش کیتا", "پیش گوئی کرنا", "پیش گوئی کردا", "پیش گوئی کررہیا", 
        "پیش گوئی کیتا", "بھولنا", "بھولدا", "بھول رہیا", "بھلیا", "اکٹھا کرنا", "اکٹھا کردا", "اکٹھا کررہیا", "اکٹھا کیتا", 
        "اندازہ لگانا", "اندازہ لگاندا", "اندازہ لگا رہیا", "اندازہ لگاییا", "سننا", "سنندا", "سن رہیا", "سنیا", "پکڑنا", 
        "پکڑدا", "پکڑ رہیا", "پکڑیا", "امید کرنا", "امید کردا", "امید کررہیا", "امید کیتا", "تصور کرنا", "تصور کردا", 
        "تصور کررہیا", "تصور کیتا", "اشارہ کرنا", "اشارہ کردا", "اشارہ کررہیا", "اشارہ کیتا", "ظاہر کرنا", "ظاہر کردا", 
        "ظاہر کررہیا", "ظاہر کیتا", "مفہوم نکالنا", "مفہوم نکالدا", "مفہوم نکال رہیا", "مفہوم نکالیا", "یقین دلانا", 
        "یقین دلاتا", "یقین دلا رہیا", "یقین دلاتا", "جج کرنا", "جج کردا", "جج کررہیا", "جج کیتا", "جاننا", "جاندا", 
        "جان رہیا", "جانیا", "سیکھنا", "سیکھدا", "سیکھ رہیا", "سیکھیا", "مطلب ہونا", "مطلب ہوندا", "مطلب ہو رہیا", 
        "مطلب ہویا", "نوٹ کرنا", "نوٹ کردا", "نوٹ کررہیا", "نوٹ کیتا", "غور کرنا", "غور کردا", "غور کررہیا", "غور کیتا", 
        "مشاہدہ کرنا", "مشاہدہ کردا", "مشاہدہ کررہیا", "مشاہدہ کیتا", "محسوس کرنا", "محسوس کردا", "محسوس کررہیا", 
        "محسوس کیتا", "قیاس کرنا", "قیاس کردا", "قیاس کررہیا", "قیاس کیتا", "فرض کرنا", "فرض کردا", "فرض کررہیا", 
        "فرض کیتا", "پیش فرض کرنا", "پیش فرض کردا", "پیش فرض کررہیا", "پیش فرض کیتا", "دکھاوا کرنا", "دکھاوا کردا", 
        "دکھاوا کررہیا", "دکھاوا کیتا", "ثابت کرنا", "ثابت کردا", "ثابت کررہیا", "ثابت کیتا", "ادراک کرنا", "ادراک کردا", 
        "ادراک کررہیا", "ادراک کیتا", "وجہ بنانا", "وجہ بناندا", "وجہ بنا رہیا", "وجہ بناییا", "یاد کرنا", "یاد کردا", 
        "یاد کررہیا", "یاد کیتا", "سمجھنا", "سمجھدا", "سمجھ رہیا", "سمجھیا", "یاد رکھنا", "یاد رکھدا", "یاد رکھ رہیا", 
        "یاد رکھیا", "ظاہر کرنا", "ظاہر کردا", "ظاہر کررہیا", "ظاہر کیتا", "دیکھنا", "دیکھدا", "دیکھ رہیا", "دیکھیا", 
        "محسوس کرنا", "محسوس کردا", "محسوس کررہیا", "محسوس کیتا", "دکھانا", "دکھاندا", "دکھا رہیا", "دکھاییا", 
        "ظاہر کرنا", "ظاہر کردا", "ظاہر کررہیا", "ظاہر کیتا", "مفہوم ہونا", "مفہوم ہوندا", "مفہوم ہو رہیا", "مفہوم ہویا", 
        "سمجھنا", "سمجھدا", "سمجھ رہیا", "سمجھیا", "شک کرنا", "شک کردا", "شک کررہیا", "شک کیتا", "سوچنا", "سوچدا", 
        "سوچ رہیا", "سوچیا", "سمجھنا", "سمجھدا", "سمجھ رہیا", "سمجھیا"
    ]
    
    # Join the list of private verbs into a pattern for regex
    pattern = r'\b(?:{})\b'.format('|'.join(map(re.escape, private_verbs)))
    
    # Tag each occurrence of the specific private verbs in the sentence
    tagged_sentence = re.sub(pattern, r'\g<0>_(PRIV)', sentence)

    return tagged_sentence


# Define the list of suasive verbs
suasive_verbs = [
    "منظور کرنا", "منظور کردا", "منظور کررہیا", "منظور کیتا",
    "اجازت دینا", "اجازت دِندا", "اجازت دے رہیا", "اجازت دِتی",
    "ترتیب دینا", "ترتیب دِندا", "ترتیب دے رہیا", "ترتیب دِتی",
    "پُچھنا", "پُچھدا", "پُچھ رہیا", "پُچھیا",
    "بِنتی کرنا", "بِنتی کردا", "بِنتی کررہیا", "بِنتی کیتی",
    "حکم دینا", "حکم دِندا", "حکم دے رہیا", "حکم دِتا",
    "تسلیم کرنا", "تسلیم کردا", "تسلیم کررہیا", "تسلیم کیتا",
    "فیصلہ کرنا", "فیصلہ کردا", "فیصلہ کررہیا", "فیصلہ کیتا",
    "مطالبہ کرنا", "مطالبہ کردا", "مطالبہ کررہیا", "مطالبہ کیتا",
    "خواہش کرنا", "خواہش کردا", "خواہش کررہیا", "خواہش کیتی",
    "تعین کرنا", "تعین کردا", "تعین کررہیا", "تعین کیتا",
    "ہدایت دینا", "ہدایت دِندا", "ہدایت دے رہیا", "ہدایت دِتی",
    "یقینی بنانا", "یقینی بناندا", "یقینی بنا رہیا", "یقینی بناییا",
    "درخواست کرنا", "درخواست کردا", "درخواست کررہیا", "درخواست کیتی",
    "عطا کرنا", "عطا کردا", "عطا کررہیا", "عطا کیتی",
    "اصرار کرنا", "اصرار کردا", "اصرار کررہیا", "اصرار کیتا",
    "ارادہ کرنا", "ارادہ کردا", "ارادہ کررہیا", "ارادہ کیتا",
    "حرکت کرنا", "حرکت کردا", "حرکت کررہیا", "حرکت کیتی",
    "آرڈر دینا", "آرڈر دِندا", "آرڈر دے رہیا", "آرڈر دِتا",
    "وعدہ کرنا", "وعدہ کردا", "وعدہ کررہیا", "وعدہ کیتا",
    "دعا کرنا", "دعا کردا", "دعا کررہیا", "دعا کیتی",
    "ترجیح دینا", "ترجیح دِندا", "ترجیح دے رہیا", "ترجیح دِتی",
    "اعلان کرنا", "اعلان کردا", "اعلان کررہیا", "اعلان کیتا",
    "تجویز کرنا", "تجویز کردا", "تجویز کررہیا", "تجویز کیتی",
    "سفارش کرنا", "سفارش کردا", "سفارش کررہیا", "سفارش کیتی",
    "عزم کرنا", "عزم کردا", "عزم کررہیا", "عزم کیتا",
    "شرط لگانا", "شرط لگاندا", "شرط لگا رہیا", "شرط لگاییا",
    "مشورہ دینا", "مشورہ دِندا", "مشورہ دے رہیا", "مشورہ دِتا",
    "ووٹ دینا", "ووٹ دِندا", "ووٹ دے رہیا", "ووٹ دِتا"
]

# Add the suasive verbs tag to sentences containing any of these verbs
def tag_suasive_verbs(text):
    for verb in suasive_verbs:
        pattern = re.compile(r'\b{}\b'.format(verb))
        text = pattern.sub(r'{}_({})'.format(verb, 'SUAV'), text)
    return text


# Define the list of indefinite pronouns
indefinite_pronouns = [
    "کوئی وی", "کوئی نہیں", "کجھ وی", "ہر کوئی", "سب کجھ", 
    "کدے نہیں", "کجھ نہیں", "کوئی اک", "کوئی"
]

# Function to tag indefinite pronouns
def tag_indefinite_pronouns(text):
    for pronoun in indefinite_pronouns:
        text = re.sub(r'\b' + re.escape(pronoun) + r'\b', f'{pronoun}_(INPR)', text)
    return text


# Define the list of other adverbial subordinates
other_adverbial_subordinates = [
    "جدوں تک", "جنی جلدی", "اس حد تک کہ", "جنا کہ", "جس دے ولوں"
]

# Function to tag other adverbial subordinates
def tag_other_adverbial_subordinates(text):
    for subordinate in other_adverbial_subordinates:
        text = re.sub(r'\b' + re.escape(subordinate) + r'\b', f'{subordinate}_(OSUB)', text)
    return text

# Define the list of amplifiers
amplifiers = [
    "مکمل", "بے حد", "پوری طرح", "انتہائی", "بہت زیادہ", "بلکل صحیح", "زور نال", "بہت"
]

# Function to tag amplifiers
def tag_amplifiers(text):
    for amplifier in amplifiers:
        text = re.sub(r'\b' + re.escape(amplifier) + r'\b', f'{amplifier}_(AMP)', text)
    return text


def tag_attributive_adjectives(text):
    # Define a pattern to match Urdu words (assuming they are in the text)
    urdu_word_pattern = r'[آ-ی]+'

    # Compile a regex pattern to find attributive adjective structures
    pattern = re.compile(fr'({urdu_word_pattern}) (\1)')

    # Use finditer to locate all matches in the text
    matches = pattern.finditer(text)

    # Initialize a list to store modified segments of text
    segments = []
    last_end = 0  # Track the end position of the last match

    # Iterate through matches and build the tagged text
    for match in matches:
        start, end = match.span()
        segments.append(text[last_end:start] + f'{match.group(1)} {match.group(2)}_(JJ)')
        last_end = end

    # Append any remaining text after the last match
    segments.append(text[last_end:])

    # Combine all segments to form the final tagged text
    tagged_text = ''.join(segments)

    return tagged_text


def tag_postpositional_phrases(text):
    # Define a pattern to match Urdu words (assuming they are in the text)
    urdu_word_pattern = r'[آ-ی]+'

    # List of postpositional phrases
    postpositional_phrases = [
        'دے', 'نال', 'توں', 'لئی', 'وچ', 'اچ', 'نوں', 'تاں'
    ]

    # Compile a regex pattern to find postpositional phrases
    pattern = re.compile(fr'({urdu_word_pattern})\s+({"|".join(postpositional_phrases)})\b')

    # Use finditer to locate all matches in the text
    matches = pattern.finditer(text)

    # Initialize a list to store modified segments of text
    segments = []
    last_end = 0  # Track the end position of the last match

    # Iterate through matches and build the tagged text
    for match in matches:
        start, end = match.span()
        segments.append(text[last_end:start] + f'{match.group(1)} {match.group(2)}_(PIN)')
        last_end = end

    # Append any remaining text after the last match
    segments.append(text[last_end:])

    # Combine all segments to form the final tagged text
    tagged_text = ''.join(segments)
    return tagged_text


def tag_present_participle(text):
    # Define patterns for present participle suffixes
    suffixes = ["دا ہویا", "دی ہوئی", "دے ہویا", "دیاں ہویاں", "ندا ہویا"]
    
    # Combine suffixes into a single regex pattern
    suffix_pattern = "|".join(suffixes)
    
    # Define a pattern to match Urdu words (assuming they are in the text)
    urdu_word_pattern = r'[آ-ی]+'
    
    # Compile a regex pattern to find present participle constructions
    # Structure 1: Object (urdu_word_pattern) + Main Verb (urdu_word_pattern) + Suffix (suffix_pattern)
    pattern1 = re.compile(fr'({urdu_word_pattern})\s+({urdu_word_pattern})\s+({suffix_pattern})')
    
    # Structure 2: Subject/Object (urdu_word_pattern) + Suffix "ندا ہویا"
    pattern2 = re.compile(fr'({urdu_word_pattern})\s+(ندا ہویا)')

    # Use finditer to locate all matches in the text
    matches1 = pattern1.finditer(text)
    matches2 = pattern2.finditer(text)

    # Initialize a list to store modified segments of text
    segments = []
    last_end = 0  # Track the end position of the last match

    # Iterate through matches of the first pattern and build the tagged text
    for match in matches1:
        start, end = match.span()
        segments.append(text[last_end:start] + f'{match.group(1)} {match.group(2)} {match.group(3)}_(PRESP)')
        last_end = end

    # Append any remaining text after the last match of pattern1
    segments.append(text[last_end:])
    text = ''.join(segments)  # Update the text

    # Reset segments and last_end for the second pattern
    segments = []
    last_end = 0

    # Iterate through matches of the second pattern and build the tagged text
    for match in matches2:
        start, end = match.span()
        segments.append(text[last_end:start] + f'{match.group(1)} {match.group(2)}_(PRESP)')
        last_end = end

    # Append any remaining text after the last match of pattern2
    segments.append(text[last_end:])
    
    # Combine all segments to form the final tagged text
    tagged_text = ''.join(segments)

    return tagged_text

def tag_past_participle(text):
    # Define suffixes for past participle
    suffixes = ["یا", "تا"]

    # Define auxiliary patterns
    auxiliaries = ["ہویا", "گیا", "سی", "نے"]

    # Combine suffixes into a single regex pattern
    suffix_pattern = "|".join(suffixes)

    # Define a pattern to match Urdu words (assuming they are in the text)
    urdu_word_pattern = r'[آ-ی]+'

    # Compile a regex pattern to find past participle constructions
    # Structure 1: Root Verb (urdu_word_pattern) + Suffix (suffix_pattern) + "ہویا" not followed by a past auxiliary
    pattern1 = re.compile(fr'({urdu_word_pattern})({suffix_pattern})\s+ہویا(?!\s+({"|".join(auxiliaries)}))')

    # Structure 2: "یا" follows "گیا"
    pattern2 = re.compile(fr'گیا\s+({urdu_word_pattern})یا')

    # Structure 3: "یا" follows an auxiliary
    pattern3 = re.compile(fr'({"|".join(auxiliaries)})\s+({urdu_word_pattern})یا')

    # Use finditer to locate all matches in the text
    matches1 = pattern1.finditer(text)
    matches2 = pattern2.finditer(text)
    matches3 = pattern3.finditer(text)

    # Initialize a list to store modified segments of text
    segments = []
    last_end = 0  # Track the end position of the last match

    # Function to replace matches with tagged text
    def replace_matches(matches, text, tag):
        segments = []
        last_end = 0
        for match in matches:
            start, end = match.span()
            segments.append(text[last_end:start] + match.group() + tag)
            last_end = end
        segments.append(text[last_end:])
        return ''.join(segments)

    # Tag matches for all patterns
    text = replace_matches(matches1, text, '_(PASTP)')
    text = replace_matches(matches2, text, '_(PASTP)')
    text = replace_matches(matches3, text, '_(PASTP)')

    return text


def tag_pied_piping_relative_clauses(text):
    # Define the pattern for Urdu words
    urdu_word_pattern = r'[آ-ی]+'
    
    # Define the WH relative clause words
    wh_relative_clauses = ["جس", "جنہاں"]
    
    # Define the postpositions
    postpositions = ["دے", "نال", "توں", "لئی", "وچ", "اچ", "نوں", "تاں"]

    # Combine WH relative clauses and postpositions into regex patterns
    wh_relative_clause_pattern = "|".join(wh_relative_clauses)
    postposition_pattern = "|".join(postpositions)
    
    # Define the pattern for structure 1
    pattern1 = re.compile(fr'({urdu_word_pattern})\s+({postposition_pattern})\s+({wh_relative_clause_pattern})')

    # Define the pattern for structure 2
    pattern2 = re.compile(fr'({urdu_word_pattern})\s+({urdu_word_pattern})\s+({wh_relative_clause_pattern})')

    # Function to replace matches with tagged text
    def replace_matches(pattern, text, tag):
        matches = pattern.finditer(text)
        segments = []
        last_end = 0
        for match in matches:
            start, end = match.span()
            segments.append(text[last_end:start] + match.group() + tag)
            last_end = end
        segments.append(text[last_end:])
        return ''.join(segments)

    # Tag matches for both patterns
    text = replace_matches(pattern1, text, '_(PIRE)')
    text = replace_matches(pattern2, text, '_(PIRE)')

    return text

def tag_independent_clause_coordinators(text):
    # Define Urdu word pattern
    urdu_word_pattern = r'[آ-ی]+'

    # Define the independent clause coordinators
    andc_words = {
        "تے": [
            (r'(auxiliary)\s+(adverb|adjective|noun|pronoun|verb)', '_(ANDC)'),
            (r'(verb)\s+(noun)', '_(ANDC)'),
            (r'complete\s+clause\s+that\s+ends\s+on\s+noun\s+(adjective)', '_(ANDC)'),
            (r'(noun)\s+(noun)', '_(ANDC)')
        ],
        "لیکن": r'(.*?)',  # Will be tagged in the entire text
        "نہ ہی": r'(.*?)',  # Will be tagged in the entire text
        "پر": r'(.*?)',  # Will be tagged in the entire text
        "اجے تک": [
            (r'کہ\s+.*?اجے تک\s+.*?کہ', '_(ANDC)'),
            (r'اجے تک\s+.*?\?', '_(ANDC)'),
            (r'اجے تک\s+.*?(نہیں|نئی)', '_(ANDC)')
        ],
        "اس لئی": r'(.*?)',  # Will be tagged in the entire text
        "تاں": [
            (r'(verb)\s+(noun|pronoun|verb)', '_(ANDC)')
        ]
    }

    def replace_matches(pattern, text, tag):
        matches = pattern.finditer(text)
        segments = []
        last_end = 0
        for match in matches:
            start, end = match.span()
            segments.append(text[last_end:start] + match.group() + tag)
            last_end = end
        segments.append(text[last_end:])
        return ''.join(segments)

    # Iterate through the independent clause coordinators
    for word, rules in andc_words.items():
        if isinstance(rules, list):
            for rule, tag in rules:
                pattern = re.compile(rule.replace('auxiliary', urdu_word_pattern).replace('adverb', urdu_word_pattern).replace('adjective', urdu_word_pattern).replace('noun', urdu_word_pattern).replace('pronoun', urdu_word_pattern).replace('verb', urdu_word_pattern))
                text = replace_matches(pattern, text, tag)
        else:
            pattern = re.compile(rules.replace('.*?', urdu_word_pattern))
            text = replace_matches(pattern, text, '_(ANDC)')
    
    return text

def detect_tags(sentence):
    tagged_sentence = sentence
    
    # Apply all functions in the sequence
    functions = [
        check_present_indefinite, check_past_indefinite, check_present_continuous, 
        check_past_continuous, check_past_perfect, check_first_person_pronoun, 
        check_second_person_pronoun, check_third_person_pronoun, check_demonstrative_pronoun, 
        check_infinitives, check_place_adverbials, check_time_adverbials, check_hedges, 
        check_pro_verb_do, check_verb_complement, check_adjective_complement, check_wh_questions,
        check_wh_subj, check_wh_obj, check_predictive_model, check_downtoners, check_emphatics, 
        check_model_of_necessity, check_discourse_particles, check_coordinate_conjunctions,
        check_conjuncts, check_conditional_subordinators, check_predictive_adjective,
        check_seem_appear, tag_words_as_vb, tag_words_as_NN, mark_split_auxiliary, tag_analytical_negation, 
        detect_synthetic_negation, check_conditional_subordinators, detect_conditional_adverbial, check_that_deletion, 
        tag_words_as_RB, tag_public_verbs, tag_private_verbs, tag_suasive_verbs, tag_indefinite_pronouns, tag_other_adverbial_subordinates, 
        tag_amplifiers, tag_attributive_adjectives, tag_postpositional_phrases, tag_present_participle, tag_past_participle,
        tag_pied_piping_relative_clauses, tag_independent_clause_coordinators
    ]
    
    for func in functions:
        tagged_sentence = func(tagged_sentence) or tagged_sentence  # Apply function or keep original
    
    return tagged_sentence


# Function to process text and display tagged sentences
def process_text():
    input_text = text_area.get("1.0", tk.END)
    sentences = input_text.split('\n')
    
    tagged_sentences = [detect_tags(sentence) for sentence in sentences if sentence.strip()]
    
    # Update output area
    output_area.config(state=tk.NORMAL)
    output_area.delete("1.0", tk.END)
    output_area.insert(tk.END, '\n'.join(tagged_sentences))
    output_area.config(state=tk.DISABLED)
    
    # Save output to Excel file
    df = pd.DataFrame(tagged_sentences, columns=["Tagged Sentences"])
    df.to_excel("tagged_sentences.xlsx", index=False)

# Function to clear the text areas
def clear_text():
    text_area.delete("1.0", tk.END)
    output_area.config(state=tk.NORMAL)
    output_area.delete("1.0", tk.END)
    output_area.config(state=tk.DISABLED)

# Create tkinter GUI
window = tk.Tk()
window.title("Punjabi MAT Tagger")

# Input text area
text_area = scrolledtext.ScrolledText(window, wrap=tk.WORD, width=60, height=15)
text_area.grid(column=0, row=0, padx=10, pady=10)

# Output text area
output_area = scrolledtext.ScrolledText(window, wrap=tk.WORD, width=60, height=15, state=tk.DISABLED)
output_area.grid(column=0, row=1, padx=10, pady=10)

# Frame for buttons
button_frame = tk.Frame(window)
button_frame.grid(column=0, row=2, padx=10, pady=5, sticky=tk.W+tk.E)

# Process button
process_button = tk.Button(button_frame, text="Process Text", command=process_text)
process_button.grid(column=0, row=0, padx=5, pady=5)

# Clear button
clear_button = tk.Button(button_frame, text="Clear Text", command=clear_text)
clear_button.grid(column=1, row=0, padx=5, pady=5)

window.mainloop()
